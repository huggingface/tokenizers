[package]
authors = ["Anthony MOI <m.anthony.moi@gmail.com>"]
edition = "2018"
name = "tokenizers"
version = "0.10.1"
homepage = "https://github.com/huggingface/tokenizers"
repository = "https://github.com/huggingface/tokenizers"
documentation = "https://docs.rs/tokenizers/"
license = "Apache-2.0"
keywords = ["tokenizer", "NLP", "huggingface", "BPE", "WordPiece"]
readme = "./README.md"
description = """
Provides an implementation of today's most used tokenizers,
with a focus on performances and versatility.
"""
exclude = [ "rust-toolchain", "target/*", "Cargo.lock", "benches/*.txt", "benches/*.json", "data/*" ]

[lib]
name = "tokenizers"
path = "src/lib.rs"
bench = false

[[bin]]
name = "cli"
path = "src/cli.rs"
bench = false

[[bench]]
name = "bpe_benchmark"
harness = false

[dependencies]
lazy_static = "1.4"
rand = "0.7"
onig = { version = "6.0", default-features = false }
regex = "1.3"
regex-syntax = "0.6"
rayon = "1.3"
rayon-cond = { version = "*", git = "https://github.com/n1t0/rayon-cond" }
serde = { version = "1.0", features = [ "derive" ] }
serde_json = "1.0"
typetag = "0.1"
clap = "2.33"
unicode-normalization-alignments = "0.1"
unicode_categories = "0.1"
indicatif = "0.14"
itertools = "0.9"

[dev-dependencies]
criterion = "0.3"
tempfile = "3.1"
