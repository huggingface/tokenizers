[package]
authors = ["Anthony MOI <m.anthony.moi@gmail.com>"]
edition = "2018"
name = "tokenizers"
version = "0.7.0"
homepage = "https://github.com/huggingface/tokenizers"
repository = "https://github.com/huggingface/tokenizers"
documentation = "https://docs.rs/tokenizers/"
license = "Apache-2.0"
keywords = ["tokenizer", "NLP", "huggingface", "BPE", "WordPiece"]
readme = "./README.md"
description = """
Provides an implementation of today's most used tokenizers,
with a focus on performances and versatility.
"""
exclude = [ "rust-toolchain", "target/*", "Cargo.lock", "benches/*.txt", "benches/*.json" ]

[lib]
name = "tokenizers"
path = "src/lib.rs"
bench = false

[[bin]]
name = "cli"
path = "src/cli.rs"
bench = false

[[bench]]
name = "bpe_benchmark"
harness = false

[dependencies]
lazy_static = "1.3.0"
rand = "0.7.2"
regex = "1.3.1"
regex-syntax = "0.6.12"
rayon = "1.2.0"
serde = "1.0"
serde_json = "1.0"
clap = "2.33.0"
unicode-normalization-alignments = "0.1.12"
unicode_categories = "0.1.1"
indicatif = "0.14.0"

[dev-dependencies]
criterion = "0.3.0"
tempfile = "3.1"
