# Minimal stub for the compiled extension module so type checkers can resolve imports
from typing import Any

AddedToken: type
Encoding: type
NormalizedString: type
PreTokenizedString: type
Regex: type
Token: type
Tokenizer: type
decoders: Any
models: Any
normalizers: Any
pre_tokenizers: Any
processors: Any
trainers: Any
__version__: str

# Re-exported implementation helpers for type checkers
BertWordPieceTokenizer: Any
ByteLevelBPETokenizer: Any
CharBPETokenizer: Any
SentencePieceBPETokenizer: Any
SentencePieceUnigramTokenizer: Any
