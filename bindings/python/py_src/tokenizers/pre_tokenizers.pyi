import tokenizers
import tokenizers.pre_tokenizers
import typing

class BertPreTokenizer:
    def __new__(cls, /) -> None: ...

class ByteLevel:
    def __new__(cls, /, add_prefix_space: bool = True, trim_offsets: bool = True, use_regex: bool = True, **_kwargs) -> None: ...
    @property
    def add_prefix_space(self, /) -> bool: ...
    @add_prefix_space.setter
    def add_prefix_space(self, /, add_prefix_space: bool) -> None: ...
    @staticmethod
    def alphabet() -> typing.Any: ...
    @property
    def trim_offsets(self, /) -> bool: ...
    @trim_offsets.setter
    def trim_offsets(self, /, trim_offsets: bool) -> None: ...
    @property
    def use_regex(self, /) -> bool: ...
    @use_regex.setter
    def use_regex(self, /, use_regex: bool) -> None: ...

class CharDelimiterSplit:
    def __getnewargs__(self, /) -> typing.Any: ...
    def __new__(cls, /, delimiter: str) -> None: ...
    @property
    def delimiter(self, /) -> str: ...
    @delimiter.setter
    def delimiter(self, /, delimiter: str) -> None: ...

class Digits:
    def __new__(cls, /, individual_digits: bool = False) -> None: ...
    @property
    def individual_digits(self, /) -> bool: ...
    @individual_digits.setter
    def individual_digits(self, /, individual_digits: bool) -> None: ...

class FixedLength:
    def __new__(cls, /, length: int = 5) -> None: ...
    @property
    def length(self, /) -> int: ...
    @length.setter
    def length(self, /, length: int) -> None: ...

class Metaspace:
    def __new__(cls, /, replacement: str = 'â–', prepend_scheme: str = ..., split: bool = True) -> None: ...
    @property
    def prepend_scheme(self, /) -> str: ...
    @prepend_scheme.setter
    def prepend_scheme(self, /, prepend_scheme: str) -> typing.Any: ...
    @property
    def replacement(self, /) -> str: ...
    @replacement.setter
    def replacement(self, /, replacement: str) -> None: ...
    @property
    def split(self, /) -> bool: ...
    @split.setter
    def split(self, /, split: bool) -> None: ...

class PreTokenizer:
    def __getstate__(self, /) -> typing.Any: ...
    def __repr__(self, /) -> str: ...
    def __setstate__(self, /, state: typing.Any) -> typing.Any: ...
    def __str__(self, /) -> str: ...
    @staticmethod
    def custom(pretok: typing.Any) -> tokenizers.pre_tokenizers.PreTokenizer: ...
    def pre_tokenize(self, /, pretok: tokenizers.PreTokenizedString) -> typing.Any: ...
    def pre_tokenize_str(self, /, s: str) -> typing.Any: ...

class Punctuation:
    def __new__(cls, /, behavior: typing.Any = ...) -> None: ...
    @property
    def behavior(self, /) -> str: ...
    @behavior.setter
    def behavior(self, /, behavior: str) -> typing.Any: ...

class Sequence:
    def __getitem__(self, /, index: int) -> typing.Any: ...
    def __getnewargs__(self, /) -> typing.Any: ...
    def __new__(cls, /, pre_tokenizers: typing.Any) -> None: ...
    def __setitem__(self, /, index: int, value: typing.Any) -> typing.Any: ...

class Split:
    def __getnewargs__(self, /) -> typing.Any: ...
    def __new__(cls, /, pattern: str | tokenizers.Regex, behavior: typing.Any, invert: bool = False) -> None: ...
    @property
    def behavior(self, /) -> str: ...
    @behavior.setter
    def behavior(self, /, behavior: str) -> typing.Any: ...
    @property
    def invert(self, /) -> bool: ...
    @invert.setter
    def invert(self, /, invert: bool) -> None: ...
    @property
    def pattern(self, /) -> typing.Any: ...
    @pattern.setter
    def pattern(self, /, _pattern: str | tokenizers.Regex) -> typing.Any: ...

class UnicodeScripts:
    def __new__(cls, /) -> None: ...

class Whitespace:
    def __new__(cls, /) -> None: ...

class WhitespaceSplit:
    def __new__(cls, /) -> None: ...
